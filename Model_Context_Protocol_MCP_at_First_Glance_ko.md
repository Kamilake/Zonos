# ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ í”„ë¡œí† ì½œ(MCP) ì²«ì¸ìƒ: MCP ì„œë²„ì˜ ë³´ì•ˆì„±ê³¼ ìœ ì§€ë³´ìˆ˜ì„± ì—°êµ¬

**ì €ì:** Mohammed Mehedi Hasan; Hao Li; Emad Fallahzadeh; Gopi Krishnan Rajbahadur; Bram Adams; Ahmed E. Hassan

**ì¶œì²˜:** arXiv:2506.13538v4 (2025ë…„ 6ì›” 20ì¼)

GPT-4ì™€ ê°™ì€ íŒŒìš´ë°ì´ì…˜ ëª¨ë¸(FM)ì€ ì ì  ... ì „í†µì ì¸ ë¶„ì„ ë° ë¦¬íŒ©í„°ë§ ê´€í–‰ì˜ ê°€ì¹˜ë¥¼ ì¬í™•ì¸í•˜ê²Œ ë§Œë“¤ê³  ìˆë‹¤.

## CCS ê°œë…

â€¢ ì†Œí”„íŠ¸ì›¨ì–´ ë° ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™ â†’ ê²½í—˜ì  ì†Œí”„íŠ¸ì›¨ì–´ ê²€ì¦.

## ì¶”ê°€ í•µì‹¬ì–´ ë° êµ¬ë¬¸

ëª¨ë¸ ì»¨í…ìŠ¤íŠ¸ í”„ë¡œí† ì½œ, MCP, ë³´ì•ˆ, ì½”ë“œ ìŠ¤ë©œ, ì†Œí”„íŠ¸ì›¨ì–´ ë²„ê·¸, ìœ ì§€ë³´ìˆ˜ì„±

## ACM ì°¸ê³  í˜•ì‹

Mohammed Mehedi Hasan, Hao Li, Emad Fallahzadeh, Gopi Krishnan Rajbahadur, Bram Adams, and Ahmed E. Hassan. TBD. Model Context Protocol (MCP) at First Glance: Studying the Security and Maintainability of MCP Servers. ACM Trans. Softw. Eng. Methodol., ( TBD), 38 pages. https://doi.org/10.1145/nnnnnnn.nnnnnnn Authorsâ€™ Contact Information: Mohammed Mehedi Hasan, mohammedmehedi.hasan@queensu.ca, Queenâ€™s University, Kingston, ON, Canada; Hao Li, Queenâ€™s University, Kingston, ON, Canada, hao.li@queensu.ca; Emad Fallahzadeh, Queenâ€™s University, Kingston, ON, Canada, emad.fallahzadeh@queensu.ca; Gopi Krishnan Rajbahadur, Queenâ€™s University, School of Computing, Kingston, Ontario, Canada, grajbahadur@acm.org; Bram Adams, Queenâ€™s University, Kingston, ON, Canada, bram.adams@queensu.ca; Ahmed E. Hassan, Queenâ€™s University, Kingston, ON, Canada, ahmed@cs.queensu.ca. Permission to make digital or hard copies of all or part of this work for personal or classroom use is granted without fee provided that copies are not made or distributed for profit or commercial advantage and that copies bear this notice and the full citation on the first page. Copyrights for components of this work owned by others than ACM must be honored. Abstracting with credit is permitted. To copy otherwise, or republish, to post on servers or to redistribute to lists, requires prior specific permission and/or a fee. Request permissions from permissions@acm.org. Â© TBD ACM. ACM 1557-7392/TBD/0-ART https://doi.org/10.1145/nnnnnnn.nnnnnnn

ì„œë¡  íŒŒìš´ë°ì´ì…˜ ëª¨ë¸(FM)(ì˜ˆ: GPT-4 [99], ...)ì´ ... ì¤‘ìš”í•œ ì†Œí”„íŠ¸ì›¨ì–´ ì°¨ì›(ì˜ˆ: ê±´ê°•ì„±, ì§€ì†ê°€ëŠ¥ì„±,

1https://github.com/Azure/azure-mcp

ë³´ì•ˆê³¼ ìœ ì§€ë³´ìˆ˜ì„±. íŠ¹íˆ, ... ì£¼ë‹¹ í‰ê·  5.5íšŒ ì»¤ë°‹(ì „í†µ ì†Œí”„íŠ¸ì›¨ì–´ 2.5íšŒ/ì£¼ ëŒ€ë¹„) ... ê°•ë ¥í•œ MCP íŠ¹í™” ì·¨ì•½ì  íƒì§€ ê¸°ë²•ê³¼ ë„êµ¬ê°€ í•„ìš”í•¨ì„ ì‹œì‚¬í•œë‹¤.
RQ-2: MCP ì„œë²„ì—ëŠ” ì–´ëŠ ì •ë„ì˜ ìœ ì§€ë³´ìˆ˜ì„± ì´ìŠˆê°€ ì¡´ì¬í•˜ëŠ”ê°€... ì½”ë“œ ìˆ˜ì¤€ ë²„ê·¸. ë³¸ ë…¼ë¬¸ì˜ ì£¼ìš” ê¸°ì—¬ëŠ” ë‹¤ìŒê³¼ ê°™ë‹¤:

(1) ë°ì´í„°ì…‹: ìš°ë¦¬ëŠ” ì˜¤í”ˆì†ŒìŠ¤ MCP ì„œë²„ì˜ ì²« íë ˆì´ì…˜ ë°ì´í„°ì…‹[57]ì„ ì œì‹œí•œë‹¤. ìˆ˜ì§‘ì€
ê³µì‹ ëª©ë¡ê³¼ GitHub ë§ˆì´ë‹ ì €ì¥ì†Œ ëª¨ë‘ì—ì„œ ì´ë£¨ì–´ì¡Œìœ¼ë©°, MCP í›„ì† ì—°êµ¬ë¥¼ ìœ„í•œ ê¸°ë°˜ ìì‚°ì´ ë  ìˆ˜ ìˆë‹¤.

(2) ë¶„ì„ í”„ë ˆì„ì›Œí¬ ë° ë² ì´ìŠ¤ë¼ì¸: ìš°ë¦¬ëŠ” í•˜ì´ë¸Œë¦¬ë“œ ë¶„ì„ í”„ë ˆì„ì›Œí¬ë¥¼ ê°œë°œÂ·ì ìš©í•œë‹¤.
ì´ëŠ” ì¼ë°˜ ëª©ì  ì •ì  ë¶„ì„ ë„êµ¬(ì˜ˆ: SonarQ...)ë¥¼ ê²°í•©í•˜ì—¬ ... ìƒˆë¡œìš´ ì˜¤í”ˆì†ŒìŠ¤ ì†Œí”„íŠ¸ì›¨ì–´ ë„ë©”ì¸ì˜ ê²½í—˜ì  ì—°êµ¬ì— í™œìš© ê°€ëŠ¥í•œ ë² ì´ìŠ¤ë¼ì¸ì„ ì œê³µí•œë‹¤.

(3) ì‹œì‚¬ì :
â€¢ ìš°ë¦¬ëŠ” MCP ìƒíƒœê³„ë¥¼ ëŒ€ìƒìœ¼ë¡œ í•œ ì²« ëŒ€ê·œëª¨ ê²½í—˜ì  ì—°êµ¬ë¥¼ ìˆ˜í–‰í•˜ë©°, ê±´ê°•ì„±,
ì§€ì†ê°€ëŠ¥ì„±, ë³´ì•ˆ, ìœ ì§€ë³´ìˆ˜ì„±ì„ ì‚´í•€ë‹¤. ... ì˜ˆ: MCP ì„œë²„ì˜ 66%ì— ì½”ë“œ ìŠ¤ë©œ, 14.4%ì— ë²„ê·¸ê°€ ìˆë‹¤.

â€¢ MCP íŠ¹í™” ì·¨ì•½ì ì€ ì „í†µì  ì·¨ì•½ì ë³´ë‹¤ ë” í”í•  ìˆ˜ ìˆì§€ë§Œ,
ì „í†µì  ë„êµ¬ì™€ ìƒˆë¡œ ë“±ì¥í•œ MCP íŠ¹í™” ë„êµ¬ ëª¨ë‘ì—ì„œ íƒì§€ê°€ ì–´ë µë‹¤ ... MCP íŠ¹í™” ì·¨ì•½ì  íƒì§€Â·ì™„í™” ê¸°ë²•ì´ í•„ìš”í•˜ë‹¤.

â€¢ MCP ì„œë²„ì˜ ìœ ì§€ë³´ìˆ˜ì„± ë¬¸ì œ(ì˜ˆ: ì½”ë“œ ìŠ¤ë©œ, ë²„ê·¸)ëŠ” ...ì™€ ë°€ì ‘íˆ ê´€ë ¨ë˜ì–´
ê¸°ì¡´ ì†Œí”„íŠ¸ì›¨ì–´ ê³µí•™ ì§€ì‹ì´ ... FMì„ í˜„ì‹¤ì—ì„œ í†µí•©í•˜ëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œìì—ê²Œ ë„ì›€ì´ ë¨ì„ ì‹œì‚¬í•œë‹¤.

Search Tool  AI ì• í”Œë¦¬ì¼€ì´ì…˜  Framework-A  Stripe Tool  Foundation...(d) MCP: í”„ë ˆì„ì›Œí¬ë¡œë¶€í„° ë„êµ¬Â·í”„ë¡¬í”„íŠ¸Â·ë¦¬ì†ŒìŠ¤ë¥¼ ë¶„ë¦¬

**ê·¸ë¦¼ 1.** FM ê¸°ë°˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ê°œë°œì„ ë™ê¸°ë¶€ì—¬í•˜ëŠ” ì˜ˆ. (a)ì—ì„œ AlexëŠ” AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ê°œë°œí–ˆê³ 

![Fig. 1 (page 5)](assets/pages/page_05.png)

framework Aë¥¼ ì‚¬ìš©í•´ ë³„ë„ì˜ ì»¤ìŠ¤í…€ ë„êµ¬ê°€ í•„ìš” ì—†ì—ˆë‹¤. (b)ì—ì„œëŠ” ...â€”ì œí’ˆ íƒìƒ‰ë¶€í„° ê²°ì œê¹Œì§€â€”ë¥¼ ë§Œë“¤ê³  ì‹¶ì§€ë§Œ ê³§ ë‹¤ìŒì„ ê¹¨ë‹«ëŠ”ë‹¤:

(1) ì œí’ˆ ê²€ìƒ‰ì—ëŠ” ì „ìš© ê²€ìƒ‰ ë©”ì»¤ë‹ˆì¦˜(ì˜ˆ: ì›¹ ê²€ìƒ‰ API)ì´ í•„ìš”í•˜ë‹¤.
(2) ì œí’ˆ ì¶”ì²œì—ëŠ” ë°œê²¬ëœ ì œí’ˆì„ ì¢…í•©Â·ìˆœìœ„í™”í•  LLMì´ í•„ìš”í•˜ë‹¤.
(3) ê²°ì œ ìˆ˜ì§‘ì—ëŠ” ê²°ì œ ê²Œì´íŠ¸ì›¨ì´(ì˜ˆ: Stripe ì—°ë™)ê°€ í•„ìš”í•˜ë‹¤.
AlexëŠ” ë„êµ¬ê°€ í•„ìš”í•˜ë‹¤ëŠ” ê²ƒì„ ë°°ì› ê³ , ë„êµ¬ëŠ” ìì²´ í¬í•¨ëœ êµ¬í˜„ì²´ì´ë‹¤... ë‹¤ì–‘í•œ ì»¤ë®¤ë‹ˆí‹°ì—ì„œ MCP ì„œë²„ê°€ ê¸‰ì¦í•˜ë©´ì„œ, ì´ì œ ë‹¤ìŒì„ ì–´ë–»ê²Œ ê²°ì •í•´ì•¼ í• ì§€ í˜¼ë€ìŠ¤ëŸ¬ì›Œì¡Œë‹¤:

(1) í•µì‹¬ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì“°ê¸°ì— ê°€ì¥ ê±´ê°•í•˜ê³  ì§€ì†ê°€ëŠ¥í•œ MCP ì„œë²„ëŠ” ë¬´ì—‡ì¸ê°€?
(RQ-0)

(2) ë¯¼ê°í•œ ê³ ê° ë°ì´í„°(ì˜ˆ: ìê²© ì¦ëª…, ì‹ ìš©ì¹´ë“œ ì •ë³´)ë¥¼ ë³´í˜¸í•˜ê¸° ìœ„í•´ MCP ì„œë²„ì˜ ë³´ì•ˆì„ ì–´ë–»ê²Œ ê²€ì¦í•  ìˆ˜ ìˆëŠ”ê°€? (RQ-1)

(3) ë²„ê·¸ë‚˜ ìŠ¤ë©œì´ ìˆì„ ê°€ëŠ¥ì„± ë“± MCP ì„œë²„ì˜ ìœ ì§€ë³´ìˆ˜ í’ˆì§ˆì„ ì–´ë–»ê²Œ í‰ê°€í•  ìˆ˜ ìˆëŠ”ê°€?

ë²„ê·¸ ë˜ëŠ” ìŠ¤ë©œ? (RQ-2) ë³¸ ì—°êµ¬ì—ì„œëŠ” ì •ëŸ‰Â·ì •ì„± ë¶„ì„ì„ í†µí•´ ì´ëŸ¬í•œ ê³¼ì œë¥¼ íƒêµ¬í•œë‹¤.
ë°°ê²½ 3.1 FM ê¸°ë°˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì„ ìœ„í•œ ë„êµ¬ í™˜ê²½ 3.... ê°œë°œ ì˜¤ë²„í—¤ë“œë¥¼ í¬ê²Œ ë‚®ì¶”ê³  ë„ì…ì„ ê°€ì†í•œë‹¤.

FM ê¸°ë°˜ AI ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœê³„ ì „ë°˜ì—ì„œ ìƒˆë¡œìš´ ë„êµ¬ì˜ ì±„íƒì„ ... REFLECTION transport: stdio  transport: stdio  ì™¸ë¶€ ì„œë¹„ìŠ¤

**ê·¸ë¦¼ 2.** MCP í´ë¼ì´ì–¸íŠ¸-ì„œë²„ ì•„í‚¤í…ì²˜ì˜ ê³ ìˆ˜ì¤€ ê°œìš”

![Fig. 2 (page 8)](assets/pages/page_08.png)

3.2.1 MCP ì›Œí¬í”Œë¡œ. ì „í˜•ì ì¸ MCP ì›Œí¬í”Œë¡œì—ì„œ AI ì• í”Œë¦¬ì¼€ì´ì…˜ì€ ... ë°ìŠ¤í¬í†± ì• í”Œë¦¬ì¼€ì´ì…˜ë¶€í„° í´ë¼ìš°ë“œ ê¸°ë°˜ ì„œë²„ ë°°í¬ê¹Œì§€ ì‚¬ìš©ëœë‹¤.

3.2.5 MCP í´ë¼ì´ì–¸íŠ¸. MCP í´ë¼ì´ì–¸íŠ¸ëŠ” ... ì¸ê¸° ìˆëŠ” ì „ì´(ê°„ì ‘) ì˜ì¡´ì„± ì²´ì¸ì— í¬í•¨ë  ë•Œ íŠ¹íˆ ì¤‘ìš”í•˜ë‹¤ [117].

2https://glama.ai/mcp/servers/@stripe/agent-toolkit

3https://glama.ai/mcp/servers/@atharvagupta2003/mcp-stripe
ì‹ í¥ ë„ë©”ì¸ìœ¼ë¡œì„œ, ìš°ë¦¬ëŠ” MCP ì„œë²„ë¥¼ ... ì—°êµ¬ê°€ ì¦ê°€í•˜ëŠ” ê²ƒë„ ê´€ì°°í–ˆë‹¤. ì—°êµ¬ ì„¤ê³„ ê°œìš”ëŠ” ê·¸ë¦¼ 3ì— ì œì‹œí•œë‹¤.

GitHubì—ì„œ MCP SDK import ë§ˆì´ë‹  ë§ˆì´ë‹ ìˆ˜: 1,556  ì „ì²´ ìˆ˜: 1,899  ì €ì¥ì†Œ ë©”íŠ¸ë¦­ í•„í„°ë§/ì €ì¥ ìˆ˜: 583

### 5.1 ë°ì´í„° ìˆ˜ì§‘

GitHubì—ì„œ í´ë¡   SonarQubeë¡œ ì •ì  ë¶„ì„  ...  ê³ ìœ  ì´ìŠˆ  LLM Jury  GPT-4o  Claude 3.7 Sonnet  Gemini 2.5 Pro

### 5.2 ì†ŒìŠ¤ ì½”ë“œ ì •ì  ë¶„ì„

### 5.3 ì´ìŠˆ í´ëŸ¬ìŠ¤í„°ë§

LLM-Juryê°€ ì‹ë³„í•œ ì´ìŠˆ íŒ¨í„´ ê²€ì¦

### 5.4 ë¹„êµ ê°€ëŠ¥í•œ ë² ì´ìŠ¤ë¼ì¸ ì°¾ê¸°

ê²€ìƒ‰ ë¬¸ìì—´ ì¤€ë¹„  ê²€ìƒ‰ ê±´ìˆ˜: 135  Google Scholar ê²€ìƒ‰  ë² ì´ìŠ¤ë¼ì¸ ì¶”ì¶œ

**ê·¸ë¦¼ 3.** ì—°êµ¬ ì„¤ê³„ ê°œìš”.

![Fig. 3 (page 11)](assets/pages/page_11.png)

5.1 ë°ì´í„° ìˆ˜ì§‘ 5.1.1 Anthropic ê³µì‹ ... Anthropicì€ MCP ì„œë²„ë¥¼ ë‘ ê°€ì§€ ì£¼ìš” ë²”ì£¼ë¡œ ë¶„ë¥˜í•œë‹¤:

â€¢ ê³µì‹ í†µí•©: ì¡°ì§ì´ ìœ ì§€Â·ê´€ë¦¬í•˜ëŠ” MCP ì„œë²„... ì˜ˆë¥¼ ë“¤ì–´, AWS MCP ì„œë²„5ëŠ”
Amazonì˜ AWS Labsì—ì„œ ìœ ì§€Â·ê´€ë¦¬í•œë‹¤.

â€¢ ì»¤ë®¤ë‹ˆí‹° ì„œë²„: ë…ë¦½ì ì¸ ì»¤ë®¤ë‹ˆí‹° êµ¬ì„±ì› ë˜ëŠ” ê¸°ì—¬ìê°€ ë‹¤ì–‘í•œ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ìœ„í•´ ê°œë°œÂ·ìœ ì§€í•˜ëŠ” MCP ì„œë²„.
ê·¸ì¤‘ í•œ ì˜ˆ... ì €ì¥ì†Œ ì´ë¦„ê³¼ GitHub URLì„ Elasticsearch ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í–ˆë‹¤.

4https://github.com/modelcontextprotocol/servers?tab=readme-ov-file

5https://github.com/awslabs/mcp

6https://github.com/66julienmartin/MCP-server-Deepseek_R1

**í‘œ 1.** í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë³„ í†µí•© ìœ í˜• ë¶„í¬

```text
Language
Official
Community
Mined
Total Count
Python
JavaScript
TypeScript
Others
Total
```

5.1.2 SDK importë¥¼ ìœ„í•œ GitHub ë§ˆì´ë‹. ìš°ë¦¬ëŠ” ... SonarQube [29] (ë„ë¦¬ ì‚¬ìš©ë˜ëŠ” ì˜¤í”ˆì†ŒìŠ¤ ë„êµ¬)ë¡œ ì •ì  ë¶„ì„ì„ ìˆ˜í–‰í–ˆë‹¤.

7https://docs.github.com/en/rest/search/search?apiVersion=2022-11-28#search-code

FindBugs [43], PMD [102]ì— ë¹„í•´ SonarQubeëŠ” ë” í­ë„“ì€ ... MITRE CWE Top

## 25 [91], OWASP Top 10 [7], PCI DSS [96]. ì·¨ì•½ì  ì™¸ì—ë„ SonarQubeëŠ” ë„ë¦¬ ì‚¬ìš©ë˜ë©°

ì½”ë“œ ìŠ¤ë©œ ë“± ìœ ì§€ë³´ìˆ˜ì„± ìš°ë ¤ë¥¼ ì‹ë³„í•˜ëŠ” ë°ë„ ì“°ì¸ë‹¤ ... SonarQubeëŠ” ë‹¤ì„¯ ê°€ì§€ ì£¼ìš” ì‹¬ê°ë„ ìœ í˜• [127]ì„ ì‚¬ìš©í•œë‹¤:

(1) Blocker: í¬ë˜ì‹œ, ë³´ì•ˆ ì¹¨í•´ ë“± ì‹¬ê°í•œ ì˜ë„ì¹˜ ì•Šì€ ê²°ê³¼ë¥¼ ìœ ë°œí•  ìˆ˜ ìˆì–´ ì¦‰ì‹œ í•´ê²°ì´ í•„ìš”í•œ ë¬¸ì œ.
ë³´ì•ˆ ì¹¨í•´ë¥¼ í¬í•¨í•˜ë©°, ì¦‰ê°ì ì¸ í•´ê²°ì´ í•„ìš”í•˜ë‹¤.
(2) Critical: ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì¹˜ëª…ì  ì˜í–¥ì„ ì£¼ëŠ” ì´ìŠˆë¡œ, ê°€ëŠ¥í•œ í•œ ë¹¨ë¦¬ ìˆ˜ì •í•´ì•¼ í•œë‹¤.
ê°€ëŠ¥í•œ í•œ ë¹¨ë¦¬.

(3) Major: ì• í”Œë¦¬ì¼€ì´ì…˜ì— í° ì˜í–¥ì„ ì£¼ëŠ” ì´ìŠˆ.
(4) Minor: ì• í”Œë¦¬ì¼€ì´ì…˜ì— ë¹„êµì  ì‘ì€ ì˜í–¥ì„ ì£¼ëŠ” ì´ìŠˆ.
(5) Info: ì• í”Œë¦¬ì¼€ì´ì…˜ì— ì˜ˆìƒë˜ëŠ” ì˜í–¥ì´ ì—†ë‹¤. ì •ë³´ ì œê³µ ëª©ì ë§Œ í•´ë‹¹.
ìš°ë¦¬ëŠ” ì´ìŠˆ ... ê¸°ì¡´ ì—°êµ¬ [79]ì— ë”°ë¼ ë©”íƒ€ë°ì´í„°(ì˜ˆ: ì´ìŠˆ ... )ë¥¼ í¬í•¨í•´ ì´ìŠˆ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì¶”ì¶œí•œë‹¤. ë˜í•œ LLM-Juryë¥¼ ì‚¬ìš©í•˜ëŠ”ë°, ì´ëŸ¬í•œ ìœ í˜•ì˜ ì‹œìŠ¤í…œì€ ...

8https://docs.sonarsource.com/sonarqube-server/10.4/extension-guide/web-api/

9https://rules.sonarsource.com/

**í‘œ 2.** ë„¤ ê°€ì§€ ê²€í†  í•­ëª©ì— ëŒ€í•´ ë¹„êµ ê°€ëŠ¥í•œ ë² ì´ìŠ¤ë¼ì¸ì„ ì°¾ê¸° ìœ„í•œ ë¬¸í—Œì¡°ì‚¬ ê²€ìƒ‰ ì „ëµ:

```text
health and sustainability metrics, security vulnerabilities, code smells, and bugs. For each item, we crafted
```

í•µì‹¬ ë³€ìˆ˜ë¥¼ í™œìš©í•´ êµ¬ì¡°í™”ëœ ê²€ìƒ‰ ë¬¸ìì—´ì„ ë§Œë“¤ê³ , ì²´ê³„ì  ... Google Scholarì—ì„œ ë¬¸í—Œ ê²€ìƒ‰ì„ ìˆ˜í–‰í–ˆìœ¼ë©°, í‘œ 2ì— ìš”ì•½í–ˆë‹¤.

ê° ê²€ìƒ‰ì—ì„œëŠ” ì£¼ìš” ë³€ìˆ˜ë¥¼(ì˜ˆ: ë©”íŠ¸ë¦­ ì´ë¦„, ë²„ê·¸ íŒ¨í„´, ë„ë©”ì¸) ë³€í˜•í•˜ì—¬ ë‹¤ì–‘í•œ ì¡°í•©ì„ ë§Œë“¤ì—ˆê³ , ê·¸ ê²°ê³¼

## ë©”íŠ¸ë¦­ì€ 96íšŒ, ì·¨ì•½ì ì€ 5íšŒ, ì½”ë“œ ìŠ¤ë©œì€ 4íšŒ, ë²„ê·¸ëŠ” 30íšŒ ê²€ìƒ‰ì„ ìˆ˜í–‰í–ˆë‹¤. ìš°ë¦¬ëŠ” ì²´ê³„ì ìœ¼ë¡œ

ê° ê²€ìƒ‰ì—ì„œ ìƒìœ„ 50ê°œ ê²°ê³¼ë¥¼ ê²€í† í•˜ê³ , ... OSS ë° ML ë² ì´ìŠ¤ë¼ì¸ê³¼ ë¹„êµí•œ ì»¤ë®¤ë‹ˆí‹° ë©”íŠ¸ë¦­/ìœ ì‚¬ ì—°êµ¬ë¥¼ í¬í•¨í–ˆë‹¤ëŠ” ì ì„ ì‹œì‚¬í•œë‹¤.

**í‘œ 3.** ì„¸ ê°€ì§€ ì—°êµ¬ ì§ˆë¬¸ì— ëŒ€í•´ ë¹„êµ ê°€ëŠ¥í•œ ë² ì´ìŠ¤ë¼ì¸ì„ ë„ì¶œí•˜ê¸° ìœ„í•´ ê²€í† í•œ 40í¸ì˜ ì—°êµ¬ ìš”ì•½

```text
questions, ordered by publication year.
RQ
Study
Purpose
RQ-0
Herraiz et al., 2009 [60]
An empirical study on OSS analyzing their evolution
Kerzazi et al., 2014 [69]
A study to measure the impact of build breakage
Borges et al., 2016 [25]
A study on the popularity of software systems hosted at GitHub
Hilton et al., 2016 [61]
Understanding the usage of CI systems
Coelho et al., 2017 [39]
Reasons Behind the Failure of Modern Open Source Projects
Baltes et al., 2018 [19]
A study on the Influence of CI on Commit Activity
Zou et al., 2019 [155]
An empirical study on branch usage in GitHub projects
Bao et al., 2019 [20]
Predicting newcomersâ€™ transition to long-term contributors
Chen et al., 2020 [33]
A study on characterizing real-world build times
Goggins et al., 2021 [53]
Exploring the metrics related to health and sustainability
Moid et al., 2021 [90]
A study to predict repository stars using smart models
Ait et al., 2022 [4]
Assessing survival rate of GitHub projects
Xiao et al., 2023 [146]
Exploring the long-term project sustainability on GitHub
He et al., 2023 [59]
A study to evaluate the effectiveness of Dependabot
Idowu et al., 2024 [64]
A study on OSS ML projects, focusing on evolution
Lai et al., 2024 [72]
Comparison between ML and non-ML issues in OSS AI projects
Bernardo et al., 2024 [22]
Exploring CI adoption practices in ML projects
RQ-1
Rahman et al., 2019 [107]
An empirical study of security smells in IaC scripts
Wist et al., 2021 [143]
An empirical study on vulnerabilities in Docker Hub images
Ruihonen et al., 2021 [113]
A security-oriented static analysis of Python packages in PyPI
Latendresse et al., 2022 [74]
Analyzing security risks of JavaScript dependencies in NPM
Zerouali et al., 2022 [153]
A study on vulnerabilities affecting NPM and RubyGems packages
Alfadel et al., 2023 [6]
An analysis of security vulnerabilities in Python packages
RQ-2
Ayewah et al., 2007 [18]
A study of warnings found by FindBugs in Java programs
Yamashita et al., 2012 [150]
How well code smells reflect factors affecting maintainability
Park et al., 2015 [101]
An analysis of HTML and CSS syntax errors
Tufano et al., 2015 [134]
Understanding when and why bad smells are introduced
Saboury et al., 2017 [116]
An empirical study of code smells in JavaScript projects
Rice et al., 2017 [110]
An algorithm to detect method argument selection bugs
Castagna et al., 2017 [30]
A type system for functional languages to support gradual typing
Chen et al., 2018 [34]
An empirical study on how defects impact maintainability
Palomba et al., 2018 [100]
Relationship between code smells and fault/change proneness
Wang et al., 2019 [140]
An approach to automatically repair buggy loops
Munoz et al., 2020 [94]
Validating cognitive complexityâ€™s impact on code understandability
Amit et al., 2021 [9]
Measuring the effort invested in bug fixing
Van Oort et al., 2021 [136]
Studying the prevalence of code smells in ML projects
Siddiq et al., 2022 [121]
A study of code smells in transformer-based code generation
Gupta et al., 2023 [55]
A severity assessment of Python code smells
Arteca et al., 2023 [15]
A study on detecting incorrect property accesses in JavaScript
Souza et al., 2024 [129]
Detecting exception-handling anti-patterns in Java, TS, and Python```

ì§€ì†ê°€ëŠ¥ì„± ì¸¡ë©´ì—ì„œë„ ê³ ë¬´ì ì´ë‹¤. ì˜ˆë¥¼ ë“¤ì–´, í‘œ 4ì— ë³´ì´ë“¯ ... MCP ì„œë²„ì˜ CI ë„ì…ë¥ ì€ 42.2%ë¡œ, ì¼ë°˜ OSS ë° ML ë„ë©”ì¸ë³´ë‹¤ ì•½ê°„ ë†’ë‹¤.

**í‘œ 4.** MCP ì„œë²„ì˜ ê°œë°œ/ì»¤ë®¤ë‹ˆí‹° ë©”íŠ¸ë¦­ì„ ì¼ë°˜ OSS ë° ML ë„ë©”ì¸ê³¼ ë¹„êµ

```text
domains. The bold ones are the age-normalized values of time-dependent metrics, e.g., which grow over time.
Metric Name
MCP Server
General OSS
Domain
ML Domain
Median Total Commit Count
```

36.3

### 608.0 [25]

### 110.0 [64]

Median Commits/Week 5.5

### 2.5 [19]

- Median Github Contributor Count 2.0

### 41.0 [25]

### 2.0 [64]

Norm. Median Github Contributor Count/year 4.0

### 61.2 [25]

- Median Follower Count Of Contributors 129.6

### 37.3 [90]

- Norm. Med. Follower Count Of Contributors/year 259.2

### 17.0 [90]

- Median Star Count 39.3

### 66.0 [59]

- Norm. Median Star Count/year 79.0

### 34.7 [59]

- Median Forks Count 9.0

### 51.0 [155]

- Norm. Median Forks Count/year 18.0

### 7.5 [155]

- Median Lines Of Code 925.2 21,168.0 [60] 2,849.0 [136] Median File Count 9.0

### 142.0 [60]

### 26.0 [64]

Median Total Github Issue Count 2.0

### 673.0 [20]

- Median Issue Lifetime in Days 5.6

### 4.0 [32]

### 25.0 [72]

CI Adoption Rate (%) 42.2

### 40.3 [61]

### 37.2 [115]

Build Success Rate(%) 90.0

### 70.0 [33]

- Median Build Duration in Mins 1.9

### 9.3 [33]

### 21.4 [22]

Median Time To Fix a Broken Build in Mins 13.9

### 46.0 [69]

- General OSS domain (40.3%) and the ML domain (37.2%). While the difference compared to general OSS is not substantial, this adoption rate is notable because prior work reports that open-source projects typically adopt CI only after one year [61], whereas our findings indicate that MCP servers often adopt CI within six months of their initial release. MCP servers also exhibit a higher median build success rate, shorter median build times, and faster resolution of broken builds compared to the baselines as shown in Table 4. According to prior research, better build-related metrics indicate that MCP servers are capable of doing more frequent releases [61], and release frequency can positively impact the development and sustainability of projects in their early stage [52]. MCP servers exhibit higher age-normalized growth in some metrics, e.g., stars and forks, despite appearing to lag behind OSS baselines in raw counts. As shown in Table 4, the median star count and fork count of MCP Servers are lower than the baselines. However, the MCP protocol was introduced only six months ago, whereas the baseline projects are much older, e.g., the median age of the projects for fork count and star count are 6.8 and 1.9 years, respectively. Hence, normalizing these metrics by project age, MCP servers demonstrate an exceptionally fast growth trajectory. Specifically, MCP servers average approximately 79 stars and 18 forks per year, surpassing the normalized rates of 34.7 stars and 7.5 per year observed in the OSS baselines. Additionally, we observe higher community reach of MCP contributors in both raw and age-normalized count of their followers. These accelerated early-stage trends suggest a promising early trajectory for sustainability within the MCP ecosystem. We find that mined MCP servers receive 101.4% more commits than community MCP servers. The median total commit count in mined, official, and community MCP servers is 44.3, 42.0, and 22.0, respectively. We use a Kruskalâ€“Wallis H-test to confirm that the differences in total

commit count among the three integration types are statistically significant (ğ»= 22, ğ‘= 0.000), and a post-hoc Mann-Whitney U test with Cliffâ€™s Delta reveals that the difference is only significant for community vs mined (ğ‘ƒğ‘ğ‘œğ‘Ÿğ‘Ÿ= 0.000 and ğ‘‘= âˆ’0.243, small effect). The difference between the other two combinations is not significant indicating that mined MCP servers have more development activities than only community servers. We also find that mined MCP servers are 56% larger than the official MCP server in terms of LoC. We observe median LoC in mined, official, and community MCP servers are 1,445.5, 929, and 548, respectively. A Kruskalâ€“Wallis H-test confirms that the differences in lines of code across the three integration types are statistically significant (ğ»= 44.4976, ğ‘< 0.0001). Post-hoc Mannâ€“Whitney U tests with Cliffâ€™s Delta reveal that mined MCP servers contain more lines of code than official MCP servers (ğ‘corr = 0.008, ğ‘‘= âˆ’0.244, small effect) and community MCP servers (ğ‘corr = 0.000, ğ‘‘= âˆ’0.345, medium effect). There is no significant difference between official and community MCP servers. Similar to the previous finding, a larger project size in mined MCP servers again demonstrates more development activities.

### Summary of RQ-0

(1) MCP servers demonstrate healthy development behaviors in terms of early-stage
health and sustainability indicators.

(2) Mined MCP servers are more active and larger in size, suggesting early adopter
momentum. 6.2 RQ-1: To what extent do MCP servers contain security vulnerabilities? Motivation. Vulnerabilities are widespread in open-source ecosystems. For example, 46% of Python packages and 40% of JavaScript packages contain at least one known security issue [74, 113]. We observe widespread adoption of these languages to build MCP servers. e.g., millions of weekly downloads of the MCP packages [11, 12], raising immediate concerns about their security posture. Moreover, the vulnerability landscape is evolving with the rise of FM-based AI tools. For instance, a recent attack targeting the FM-based code editor and MCP client â€œCursorâ€ 10 leveraged three malicious NPM packages to exfiltrate credentials from over 4,200 users.11 This example highlights the broader risks of MCP servers as they mediate access between FMs and external systems, a dimension that has not existed before. In particular, MCP servers, deployed locally or remotely, act as intermediaries connecting FMs with sensitive resources, e.g., file systems, databases, and API endpoints. As a result, MCP servers often handle confidential data, including credentials, API keys, and user information. This tight coupling with critical infrastructure makes MCP servers attractive targets for exploitation. Despite this, the extent to which MCP servers are vulnerable remains unknown. Motivated by these emerging threat landscapes, we investigate the extent and nature of vulnerabilities present in MCP servers. Specifically, this research question aims to characterize the prevalence and patterns of security vulnerabilities in MCP servers, comparing those with the reported vulnerabilities from other domains in previous literature and assessing whether current tools and techniques are sufficient to detect the unique vulnerability landscape of MCP servers. Approach. To extract vulnerability issues from MCP servers, we perform static analysis on their codebases using SonarQube, as detailed in Section 5.2.1. Out of five major severity categories of SonarQube, in this RQ, we focus on the first four severity levels: Blocker, Critical, Major, and Minor.

10https://www.cursor.com/en

11https://thehackernews.com/2025/05/malicious-npm-packages-infect-3200.html

ìš°ë¦¬ëŠ” ì´ëŸ¬í•œ ë²”ì£¼ì— ì†í•˜ëŠ” ëª¨ë“  ì·¨ì•½ì ì„ ... 42ê°œì˜ ê³ ìœ í•œ MCP ì„œë²„ì—ì„œ ì¶”ì¶œí–ˆìœ¼ë©°, ì´ëŠ”

## 13ê°œì˜ CWEì™€ ë°€ì ‘í•˜ê²Œ ê´€ë ¨ëœë‹¤. ì´ë“¤ CWE ì¤‘ ë‹¤ìˆ˜ëŠ” ë‹¤ë¥¸ ë„ë©”ì¸ì—ì„œ ë³´ê³ ëœ CVEì˜ ê·¼ë³¸ ì›ì¸ì´ê¸°ë„ í•˜ë©°,

í‘œ 6ì— ë³´ê³ ëœ ë°”ì™€ ê°™ì´, ì·¨ì•½ì  ... MCP ì„œë²„ ì„¤ì¹˜ë¿ ì•„ë‹ˆë¼ ê·¸ì— ëŒ€í•œ ...ë„ í•„ìš”í•¨ì„ ì‹œì‚¬í•œë‹¤.

12https://next.sonarqube.com/sonarqube/coding_rules?open=secrets:S7219&rule_key=secrets:S7219

**í‘œ 5.** MCP ì„œë²„, PyPI íŒ¨í‚¤ì§€, NPM íŒ¨í‚¤ì§€, IaC ìŠ¤í¬ë¦½íŠ¸ ì „ë°˜ì˜ ì·¨ì•½ì  íŒ¨í„´(ìœ ë³‘ë¥  ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬)

```text
descending order of prevalence. Highlighted patterns indicate cross-domain similarities, with superscript
```
ìˆ«ìì™€ ìƒ‰ì€ ê°€ì¥ ê°€ê¹Œìš´ ì˜ë¯¸ì  ë§¤ì¹­ì„ ë‚˜íƒ€ë‚¸ë‹¤. ì˜ˆë¥¼ ë“¤ì–´ ... Code Execution  Authentication Bypass2  Arbitrary Code Injection

**í‘œ 6.** MCP ì„œë²„ì—ì„œì˜ ì·¨ì•½ì  íŒ¨í„´ ìœ ë³‘ë¥ ê³¼, ê°€ì¥ ê´€ë ¨ì´ ê¹Šì€ CWE ë°

```text
example CVEs caused by those CWEs.
MCP Vulnerabilities
```

% of MCP Servers Related CWEs Example CVEs Caused by CWEs Credential Exposure 3.6% CWE-259, CWE-798 CVE-2022-29964 Lack of Access Control 1.4% CWE-306, CWE-284 CVE-2022-24985 CORS Issues 1.2% CWE-345 â€“ Improper Resource Management 1.0% CWE-770 CVE-2022-23471 Transport Security Issues 0.7% CWE-295, CWE-297, CWE-327 CVE-2021-22909 Authentication Issues 0.5% CWE-347 CVE-2002-1796 Insecure File Creation 0.2% CWE-377 CVE-2022-41954 Input Validation Issues 0.2% CWE-611 CVE-2022-42745 complete runtime configuration, including API credentials and auxiliary services. Despite following these steps, in our initial attempt to scan a representative sample of 83 MCP servers, only 60 scans were successful, with the remainder failing due to an issue within the tool. After we reported this to the maintainers, they released a fixed version that enabled us to successfully scan an additional
MCP ì„œë²„ ë¹„ìœ¨  ê´€ë ¨ CWE  í•´ë‹¹ CWEë¡œ ì¸í•´ ë°œìƒí•œ ì˜ˆì‹œ CVE ... ì¶”ê°€ë¡œ 13ê°œ ì„œë²„ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìŠ¤ìº”í•  ìˆ˜ ìˆì—ˆë˜ ìˆ˜ì • ë²„ì „ ë•ë¶„ì—,
## 13 servers, bringing our total to 73. These events highlight that such MCP-specific tools are still
## ì´ 13ê°œ ì„œë²„ë¥¼ ë”í•´ ì „ì²´ 73ê°œê°€ ë˜ì—ˆë‹¤. ì´ëŸ¬í•œ ì‚¬ê±´ì€ MCP íŠ¹í™” ë„êµ¬ê°€ ì•„ì§
evolving in their early lifecycle. Despite the operational challenges and early stage of the tool, we still detect potential tool poisoning in 5.5% of MCP servers, which is more prevalent than credential exposure. The ability of an early-stage tool, deployed with considerable effort on a limited sample, to uncover
ì´ˆê¸° ë¼ì´í”„ì‚¬ì´í´ì—ì„œ ì§„í™” ì¤‘ì„ì„ ë³´ì—¬ì¤€ë‹¤. ìš´ì˜ìƒì˜ ì–´ë ¤ì›€ì—ë„ ë¶ˆêµ¬í•˜ê³  ...
this rate of a critical MCP-specific vulnerability strongly underscores the likelihood of more hidden issues that existing tools are currently unable to detect. While mcp-scan is able to detect tool poisoning, it misses other security concerns, such as excessive permission requirements and insecure default behaviors. During the setup process, we manually uncovered several concerning patterns that were not flagged by the scanner. For instance, the apple-notes-mcp server13 requires full disk access on macOS to interact with the native Apple Notes SQLite database highlighting an overly privileged configuration that which can introduce a significant attack surface. Similarly, godot-mcp14 was configured with autoapproval enabled for sensitive operations such as stopping projects or modifying project identifiers, potentially allowing unvetted commands to be executed. These issues are missed by mcp-scan because it relies on tool descriptions obtained through reflection rather than analyzing the source code, limiting its ability to catch deeper or context-specific security flaws. Pure MCP servers are more prone to credential exposure and transport security issues than the MCP servers derived from other applications, in which 85% of the identified vulnerabilities are found in deployment files. To better understand MCP server vulnerabilities, we analyze five random MCP servers that are â€œpureâ€ MCP implementations without inherited legacy code or multifunctional roles. The most common vulnerabilities in these projects are credential exposure and transport security issues. For instance, we identify transport security issues, e.g., SSL/TLS verification bypasses in sooperset/mcp-atlassian and tuanle96/mcp-odoo, while credential exposure was prevalent in amornpan/py-mcp-mssql, kiliczsh/mcp-mongo-server, and Matmax-Worldwide/payloadcmsmcp. Then, we analyze the projects with more than five identified vulnerabilities. We found that only five MCP serversâ€”SciPhi-AI/R2R, alibaba/higress, devflowinc/trieve, get-convex/convex-backend, and anaversity/learn-agentic-aiâ€”fit this criterion and in these servers 85% vulnerabilities are found in â€œ.yamlâ€ files. At the same time, all the MCP servers with more than five vulnerabilities have implemented MCP as an additional feature in addition to their current functionalities. This highlights that the vulnerabilities in pure MCP repositories and other repositories where MCP is a derived feature need to be studied differently. The traditional vulnerability scanner SonarQube cannot detect any vulnerabilities in official MCP servers. Figure 4 illustrates the distribution of vulnerability counts per server, grouped by integration type (official, community, and mined) where both community and mined MCP servers have a median vulnerability count of 2, while no vulnerability is found in official MCP servers. Interestingly, this mirrors findings from the Docker ecosystem, where official images have been shown to exhibit fewer vulnerabilities compared to community-maintained ones [143]. We detect exposed OpenAI and Gemini API keys, Google Cloud service account certificates, and GitHub tokens in community and mined MCP server repositories, posing significant risks of financial loss and unauthorized access. Figure 5 presents three representative examples of such credential exposures across JSON, Python, and certificate files from real-world repositories. Leaked API keys for platforms like OpenAI and Google Cloud can be exploited by malicious actors to initiate high-volume API calls, potentially resulting in substantial financial charges for the affected account owners. Likewise, exposed GitHub tokens may allow unauthorized access to private repositories or CI/CD pipelines. As shown in Table 6, these are indicative of CWE-798 (Use of Hardcoded Credentials), which has been associated with several previous high-impact security incidents, including CVE-2022-29964.
ìš´ì˜ìƒì˜ ì–´ë ¤ì›€ì—ë„ ... ì œí•œëœ í‘œë³¸ì—ì„œ ìƒë‹¹í•œ ë…¸ë ¥ìœ¼ë¡œ ë„êµ¬ë¥¼ ë°°í¬í•´,
13https://github.com/sirmews/apple-notes-mcp
ì´ëŸ¬í•œ ì¹˜ëª…ì ì¸ MCP íŠ¹í™” ì·¨ì•½ì ì˜ ë¹„ìœ¨ì€ ... CVE-2022-29964ë¥¼ í¬í•¨í•œ ì—¬ëŸ¬ ê³ ì˜í–¥ ë³´ì•ˆ ì‚¬ê³ ì™€ ì—°ê²°ë¨ì„ ê°•í•˜ê²Œ ì‹œì‚¬í•œë‹¤.
14https://github.com/Coding-Solo/godot-mcp

official community mined Integration Type Vulnerability Count per MCP Server Integration Type Official Community Mined
ê³µì‹  ì»¤ë®¤ë‹ˆí‹°  ë§ˆì´ë‹  í†µí•© ìœ í˜•  MCP ì„œë²„ë‹¹ ì·¨ì•½ì  ìˆ˜  í†µí•© ìœ í˜•  ê³µì‹  ì»¤ë®¤ë‹ˆí‹°  ë§ˆì´ë‹
**ê·¸ë¦¼. 4.** Vulnerability count distribution per MCP server grouped by Integration Type.
**ê·¸ë¦¼ 4.** í†µí•© ìœ í˜•ë³„ë¡œ ê·¸ë£¹í™”í•œ MCP ì„œë²„ë‹¹ ì·¨ì•½ì  ìˆ˜ ë¶„í¬.
![Fig. 4 (page 22)](assets/pages/page_22.png)

OPENAI_API_KEY ": "sk-Wo ******** g5" (a) Hardcoded OpenAI API key in a JSON configuration file. # Configure Gemini genai.configure(api_key='AIza **** -****1 zn4') model = genai.GenerativeModel('gemini -2.0-flash -001') (b) Gemini API key exposed directly in Python source code. "type": "service_account", "project_id ": "***", "private_key_id ": "d4d ****4a4", "private_key ": "-----BEGIN PRIVATE KEY -----\***\n-----END PRIVATE KEY -----\n", "universe_domain ": "googleapis.com" (c) Google Cloud service account private key exposed in a certificate file.
OPENAI_API_KEY ": "sk-Wo ******** g5" (a) í•˜ë“œì½”ë”©ëœ OpenAI API í‚¤ ... í´ë¼ìš°ë“œ ì„œë¹„ìŠ¤ ê³„ì • ê°œì¸ í‚¤ê°€ ì¸ì¦ì„œ íŒŒì¼ì—ì„œ ë…¸ì¶œëœ ì‚¬ë¡€.
**ê·¸ë¦¼. 5.** Examples of credential exposure across different code and configuration formats. As these are sensitive
**ê·¸ë¦¼ 5.** ë‹¤ì–‘í•œ ì½”ë“œ/ì„¤ì • í˜•ì‹ì—ì„œì˜ ìê²© ì¦ëª… ë…¸ì¶œ ì˜ˆì‹œ. (ë¯¼ê° ì •ë³´ì´ë¯€ë¡œ ...)
![Fig. 5 (page 22)](assets/pages/page_22.png)

credentials and keys we have obfuscated those.

### Summary of RQ-1

(1) MCP servers exhibit distinct vulnerability patterns compared to other domains of
software engineering. Out of eight vulnerability patterns detected in MCP servers, three are common with other domains.

(2) MCP-specific vulnerabilities can be highly prevalent as even an early stage tool could
already detect 5.5% MCP-specific issues.

(3) Credential exposure, e.g., API Keys from FM service providers, GitHub tokens, can
cause significant financial loss and major data breaches. RQ-2: To what extent do MCP servers contain maintainability issues? Motivation. Maintainability remains a pressing concern in modern software systems, especially in the era of FM-based AI applications. According to the State of Software-2025 report [54], 73% of AI and big data systems fall below the industry benchmark for maintainability. In mature organizations,
ìœ ì§€ë³´ìˆ˜ì„± ì´ìŠˆë¥¼ í•´ê²°í•˜ê¸° ìœ„í•œ ì˜¤ë²„í—¤ë“œëŠ” ìµœëŒ€ Â£25... í‘œ 8. íŠ¹íˆ MCPì—ì„œ ì„ê³„(critical) ì½”ë“œ ìŠ¤ë©œì˜ ì¤‘ì•™ê°’ì€ ...

**í‘œ 7.** MCP ì„œë²„, ML í”„ë¡œì íŠ¸, FM ìƒì„± ì½”ë“œ ì „ë°˜ì˜ ì½”ë“œ ìŠ¤ë©œ íŒ¨í„´(ìœ ë³‘ë¥  ë‚´ë¦¼ì°¨ìˆœ)

```text
in descending order. The first column (MCP server) includes prevalence percentages. Highlighted patterns
```

ë„ë©”ì¸ ê°„ ìœ ì‚¬ì„±ì„ ë‚˜íƒ€ë‚´ë©°, ìœ„ì²¨ì ë²ˆí˜¸ì™€ ìƒ‰ìœ¼ë¡œ ... Issues (1.2%) missing-module-docstring1 Consider-usingenumerate4

**í‘œ 8.** í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë³„ Critical/Blocker ì½”ë“œ ìŠ¤ë©œ ë¶„í¬. Critical smell %

```text
and Blocker smell % indicate the percentage of projects where at least one critical or blocker-level code
```

smell is present. Median Critical and Median Blocker represent the median number of critical and blocker code smells per project, respectively. Language Critical smell % Median Critical Blocker smell % Median Blocker Python 68.1 1.0 5.6 JavaScript 39.8 2.0 1.3 TypeScript 61.1 4.0 5.8 Others 47.3 12.0 4.4 servers ranges between 2 and 4 in the most commonly used programming languages, e.g., Python, JavaScript, and TypeScript, while the median number of blocker-level code smells is zero across all these languages. In contrast, traditional software engineering studies have reported that certain code smells can be present in nearly 100% of the studied Python ML projects and traditional Python projects [35, 136] and up-to 97% FM generated code can contain code smells [121]. 59.7% of MCP servers suffer from high cognitive complexity, which is also considered as the one of the most severe code smells in Python ecosystem. As summarized in Table 7, we observe that high cognitive complexity is almost three times more prevalent than the second most common code smell, e.g., code duplication-redundancy, in MCP servers. Cognitive complexity is a widely used metric for modeling and estimating the functional complexity, size, and effort required for software development [141]. While prior studies suggest a threshold of 15 for cognitive complexity [94], violation of this threshold is considered the one of the most severe code smells in the Python ecosystem [55]. Similarly, this threshold is violated in a substantial portion (59.7%) of MCP servers, which can lead to increased comprehension time, reduced understandability, and higher debugging time and error rates [94]. Mined MCP servers contain 66% more code smells than both official and community servers. Figure 6a presents the distribution of code smell counts per MCP server across different

integration types on a logarithmic scale. We observe a median code smell count of 5 in mined MCP servers, compared to 3 in official and community MCP servers. A Kruskal-Wallis H-test reveals a significant difference in code smell counts among the three integration types (ğ»= 23.2936, ğ‘< 0.001). Post-hoc Mann-Whitney U tests indicate that mined servers have more code smells than both official (ğ‘ƒâˆ’ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’= 0.004 and ğ‘‘= âˆ’0.322, small effect) and community (ğ‘ƒâˆ’ğ‘£ğ‘ğ‘™ğ‘¢ğ‘’= 0.000 and ğ‘‘= âˆ’0.280, small effect) servers. However, the difference between official and community MCP servers is not statistically significant. We can partially explain by the larger size of mined MCP servers found in Section 6.1, as prior work [149] has shown a positive correlation between code size and code smells. official community mined Integration Type Codesmell Count per MCP Server (log) (a) Code smell count distribution by integration type in logarithmic scale. Python JavaScript TypeScript Programming Language Codesmell Count per MCP Server (log) (b) Code smell count distribution by programming language in logarithmic scale.

**Fig. 6.** Comparison of code smells by integration type and programming language.

![Fig. 6 (page 25)](assets/pages/page_25.png)

JavaScript MCP ì„œë²„ëŠ” ... ì½”ë“œ ìŠ¤ë©œì´ 50% ì ì€ ê²½í–¥ì´ ìˆë‹¤... êµ¬ì¡°(Architecture) ì´ìŠˆëŠ” Java ìƒíƒœê³„ì—ì„œ ë³´ê³ ëœ ë²„ê·¸ì—ëŠ” ë‚˜íƒ€ë‚˜ì§€ ì•ŠëŠ”ë‹¤.

**í‘œ 9.** MCP ì„œë²„ì™€ Java í”„ë¡œì íŠ¸ì—ì„œì˜ ìƒìœ„ ë²„ê·¸ ìœ í˜• ë° ë¶„í¬. MCP ì„œë²„ ë¹„ìœ¨ì€

```text
are shown in parentheses. The table is sorted in descending order of prevalence. Highlighted patterns indicate
```

ë„ë©”ì¸ ê°„ ìœ ì‚¬ì„±ì„ ë‚˜íƒ€ë‚´ë©°, ìœ„ì²¨ì ë²ˆí˜¸ì™€ ìƒ‰ìœ¼ë¡œ ... (1.7%) Field only ever set to null  Suspicious reference comparison

**í‘œ 10.** í”„ë¡œê·¸ë˜ë° ì–¸ì–´ë³„ Critical/Blocker ë²„ê·¸ ë¶„í¬. Critical bug % ë°

```text
Blocker bug % indicate the percentage of projects where at least one critical or blocker-level bug is present.
Median Critical and Median Blocker represent the median number of critical and blocker bugs per project,```

ê°ê°. ì–¸ì–´ë³„ Critical bug % ë° ì¤‘ì•™ê°’(Critical/Blocker) ... ê·¸ë¦¼ 7aì˜ í•´ë‹¹ ë°”ì´ì˜¬ë¦° í”Œë¡¯ ë¶„í¬ë¥¼ ì°¸ê³ í•˜ë¼. ë‹¤ë§Œ

15https://v8.dev/blog/array-sort

Python  JavaScript  TypeScript  í”„ë¡œê·¸ë˜ë° ì–¸ì–´  ë²„ê·¸ ìˆ˜ ... (b) í†µí•© ìœ í˜•ë³„ MCP ì„œë²„ë‹¹ ë²„ê·¸ ë¶„í¬.

**ê·¸ë¦¼ 7.** MCP ì„œë²„ ì „ë°˜ì—ì„œ í†µí•© ìœ í˜• ë° í”„ë¡œê·¸ë˜ë° ì–¸ì–´ì— ë”°ë¥¸ ë²„ê·¸ ë¹„êµ.

![Fig. 7 (page 27)](assets/pages/page_27.png)

í‘œë¥¼ ë³´ë©´ TypeScriptê°€ ë” ì·¨ì•½í•  ìˆ˜ ... ì´ëŠ” ë²„ê·¸ ë„ì… ê°€ëŠ¥ì„± ì¦ê°€ì™€ ì—°ê´€ë  ìˆ˜ ìˆë‹¤ [50].

### RQ-2 ìš”ì•½

(1) 66% of MCP servers contain at least one critical or blocker-level code smell, and 14.4%
ì •ì  ë¶„ì„ìœ¼ë¡œ íƒì§€ëœ ë²„ê·¸ê°€ ìµœì†Œ 1ê°œ ì´ìƒ ... ê´‘ë²”ìœ„í•œ ìœ ì§€ë³´ìˆ˜ì„± ìš°ë ¤ë¥¼ ë³´ì—¬ì¤€ë‹¤.

(2) ê°€ì¥ í”í•œ ì½”ë“œ ìŠ¤ë©œì€ ë†’ì€ ì¸ì§€ ë³µì¡ë„ì´ë©°, MCP ì„œë²„ì˜ 59.7%ì— ì˜í–¥ì„ ì¤€ë‹¤.
ì´ëŠ” ë‘ ë²ˆì§¸ë¡œ í”í•œ ìŠ¤ë©œë³´ë‹¤ 3ë°° ... ê°€ë…ì„±/ì´í•´ë„ ì €í•˜ ë° ì˜¤ë¥˜ ìœ„í—˜ ì¦ê°€ì™€ ê°•í•˜ê²Œ ì—°ê´€ëœë‹¤.

(3) ë§ˆì´ë‹ëœ MCP ì„œë²„ëŠ” ê³µì‹/ì»¤ë®¤ë‹ˆí‹° ì„œë²„ë³´ë‹¤ ì½”ë“œ ìŠ¤ë©œê³¼ ë²„ê·¸ê°€ ë” ë§ë‹¤.
ì´ëŠ” ê°œë°œ í™œë™ì´ ë” í™œë°œí•˜ê±°ë‚˜, ìœ ì§€ë³´ìˆ˜ ê´€í–‰ì´ ëœ êµ¬ì¡°í™”ë˜ì–´ ìˆê¸° ë•Œë¬¸ì¼ ìˆ˜ ìˆë‹¤.

(4) ì‹ë³„ëœ ëª¨ë“  MCP ë²„ê·¸ ìœ í˜•ì€ Java, Python, JavaScript ìƒíƒœê³„ì—ì„œ ì•Œë ¤ì§„ ë²„ê·¸ì™€ ê²¹ì¹œë‹¤.
ë”°ë¼ì„œ ê¸°ì¡´ ë””ë²„ê¹… ë° ... MCP ì„œë²„ì—ë„ ì ìš©ë  ìˆ˜ ìˆìŒì„ ì‹œì‚¬í•œë‹¤. íŠ¹íˆ MCP ìƒíƒœê³„ì—ëŠ” ì„¸ ê°€ì§€ ì£¼ìš” ëŒ€ìƒì´ ìˆë‹¤:

MCP ìƒíƒœê³„ì˜ ëŒ€ìƒ: (i) ì—°êµ¬ì, (ii) ì‹¤ë¬´ì, (...) ì „í†µ ì†Œí”„íŠ¸ì›¨ì–´ ë„ë©”ì¸(6.2ì ˆ)ê³¼ì˜ ìœ ì‚¬ì„±. ì´ëŸ¬í•œ ìœ ì‚¬ì„±ì€

16https://genai.owasp.org/llm-top-10/
ì´ëŠ” ì‹¤ë¬´ìê°€ ì „í†µì ìœ¼ë¡œ ì˜ í™•ë¦½ëœ ê¸°ë²•ì„ ... MCP ì¸í”„ë¼ ì±„íƒì´ ëŠ˜ì–´ë‚¨ì— ë”°ë¼ ì§„í™”í•  ê²ƒì´ë‹¤.

17https://www.reddit.com/r/mcp/comments/1hm3g2s/glama_mcp_server_directory/

íƒ€ë‹¹ì„± ìœ„í˜‘ 8.1 ì™¸ì  íƒ€ë‹¹ì„± ë³¸ ì—°êµ¬ì—ì„œëŠ” ... ì·¨ì•½ì ë¿ ì•„ë‹ˆë¼ ì½”ë“œ ìŠ¤ë©œê³¼ ë²„ê·¸ê¹Œì§€ë„ í¬í•¨í•œë‹¤.

8.3 ë‚´ì  íƒ€ë‹¹ì„± ë³¸ ì—°êµ¬ì—ì„œëŠ” ì˜¤í”ˆì†ŒìŠ¤ ... MCP ì„œë²„ë¥¼ ì¡°ì‚¬í–ˆìœ¼ë©°, ê·¸ì¤‘ ê³µí†µ ì´ìŠˆì™€ ê²¹ì¹˜ëŠ” ê²ƒì€ 3ê°œë¿ì´ì—ˆë‹¤ ...
Pythonì´ë‚˜ Infrastructure-as-Code ê°™ì€ ìƒíƒœê³„ ... ì¶”ê°€ì ìœ¼ë¡œ ...

## ì°¸ê³ ë¬¸í—Œ(ì›ë¬¸)

[20] Lingfeng Bao, Xin Xia, David Lo, and Gail C Murphy. 2019. A large scale study of long-time contributor prediction for github projects. IEEE Transactions on Software Engineering 47, 6 (2019), 1277â€“1298. [21] Setu Kumar Basak, Lorenzo Neil, Bradley Reaves, and Laurie Williams. 2022. What are the practices for secret management in software artifacts?. In 2022 IEEE Secure Development Conference (SecDev). IEEE, 69â€“76. [22] JoÃ£o Helis Bernardo, Daniel Alencar Da Costa, SÃ©rgio Queiroz de Medeiros, and UirÃ¡ Kulesza. 2024. How do machine learning projects use continuous integration practices? an empirical study on GitHub actions. In Proceedings of the 21st International Conference on Mining Software Repositories. 665â€“676. [23] Ethan Bommarito and Michael Bommarito. 2019. An empirical analysis of the python package index (pypi). arXiv preprint arXiv:1907.11073 (2019). [24] Rishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx, Michael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. 2021. On the opportunities and risks of foundation models. arXiv preprint arXiv:2108.07258 (2021). [25] Hudson Borges, Andre Hora, and Marco Tulio Valente. 2016. Understanding the factors that impact the popularity of GitHub repositories. In 2016 IEEE international conference on software maintenance and evolution (ICSME). IEEE, 334â€“344. [26] Tom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal, Arvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. 2020. Language models are few-shot learners. Advances in neural information processing systems 33 (2020), 1877â€“1901. [27] Simon Butler, Jonas Gamalielsson, BjÃ¶rn Lundell, Christoffer Brax, Anders Mattsson, Tomas Gustavsson, Jonas Feist, Bengt KvarnstrÃ¶m, and Erik LÃ¶nroth. 2022. Considerations and challenges for the adoption of open source components in software-intensive businesses. Journal of Systems and Software 186 (2022), 111152. [28] Paolo Calciati and Alessandra Gorla. 2017. How do apps evolve in their permission requests? a preliminary study. In

## 2017 IEEE/ACM 14th International Conference on Mining Software Repositories (MSR). IEEE, 37â€“41.

[29] G Ann Campbell and Patroklos P Papapetrou. 2013. SonarQube in action. Manning Publications Co. [30] Giuseppe Castagna and Victor Lanvin. 2017. Gradual typing with union and intersection types. Proceedings of the ACM on Programming Languages 1, ICFP (2017), 1â€“28. [31] CHAOSS Project. 2025. Community Health Analytics in Open Source Software: Topic - All Metrics. https://chaoss. community/kbtopic/all-metrics/. Accessed: Jun 10, 2025. [32] CHAOSS Project. 2025. Practitioner Guide: Responsiveness. https://chaoss.community/practitioner-guideresponsiveness/. Accessed: May 15, 2025. [33] Bihuan Chen, Linlin Chen, Chen Zhang, and Xin Peng. 2020. Buildfast: History-aware build outcome prediction for fast feedback and reduced cost in continuous integration. In Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering. 42â€“53. [34] Celia Chen, Shi Lin, Michael Shoga, Qing Wang, and Barry Boehm. 2018. How do defects hurt qualities? an empirical study on characterizing a software maintainability ontology in open source software. In 2018 IEEE International Conference on Software Quality, Reliability and Security (QRS). IEEE, 226â€“237. [35] Zhifei Chen, Lin Chen, Wanwangying Ma, and Baowen Xu. 2016. Detecting code smells in python programs. In 2016 international conference on Software Analysis, Testing and Evolution (SATE). IEEE, 18â€“23. [36] Henry Chesbrough. 2023. Measuring the economic value of open source. San Francisco: Linux Foundation (2023). [37] Steve Christey and Robert A Martin. 2007. Vulnerability type distributions in CVE. Mitre report, May (2007). [38] Cloudflare. 2025. Cloudflare Agents Docs: Model Context Protocol (MCP). https://developers.cloudflare.com/agents/ model-context-protocol, last visited: Apr 23. [39] Jailton Coelho and Marco Tulio Valente. 2017. Why modern open source projects fail. In Proceedings of the 2017 11th Joint meeting on foundations of software engineering. 186â€“196. [40] CrewAI. 2025. CrewAI: The leading multi-agent platform. https://www.crewai.com/, last visited: May 27. [41] Dinis Barroqueiro Cruz, JoÃ£o Rafael Almeida, and JosÃ© LuÃ­s Oliveira. 2023. Open source solutions for vulnerability assessment: A comparative analysis. IEEE Access 11 (2023), 100234â€“100255. [42] Ozren Dabic, Emad Aghajani, and Gabriele Bavota. 2021. Sampling projects in github for MSR studies. In 2021 IEEE/ACM 18th International Conference on Mining Software Repositories (MSR). IEEE, 560â€“564. [43] Andrey Loskutov Keith Lea David Hovemeyer, Bill Pugh. 2025. An extensible multilanguage static code analyzer. https://findbugs.sourceforge.net/, last visited: May 18. [44] DI De Silva, RD New Kandy, BLO Sachethana, SMDTH Dias, PYC Perera, ME Katipearachchi, and TDDH Jayasuriya. 2023. The Relationship between Code Complexity and Software Quality: An Empirical Study. Journal of Software Engineering Research and Development 11, 1 (2023), 1. [45] Alexandre Decan, Tom Mens, and Eleni Constantinou. 2018. On the impact of security vulnerabilities in the npm package dependency network. In Proceedings of the 15th international conference on mining software repositories. 181â€“191.

[46] Kerstin Denecke, Richard May, LLMHealthGroup, and Octavio Rivera Romero. 2024. Potential of large language models in health care: Delphi study. Journal of Medical Internet Research 26 (2024), e52399. [47] Dify. 2025. Dify: Build Production Ready Agentic Solution. https://dify.ai/, last visited: May 27. [48] Inc Docker et al. 2020. Docker. lÄ±nea].[Junio de 2017]. Disponible en: https://www. docker. com/what-docker (2020). [49] Tore DybÃ¥, Vigdis By Kampenes, and Dag IK SjÃ¸berg. 2006. A systematic review of statistical power in software engineering experiments. Information and Software Technology 48, 8 (2006), 745â€“755. [50] Filipe FalcÃ£o, Caio Barbosa, Baldoino Fonseca, Alessandro Garcia, MÃ¡rcio Ribeiro, and Rohit Gheyi. 2020. On relating technical, social factors, and the introduction of bugs. In 2020 IEEE 27th International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, 378â€“388. [51] Rosa Falotico and Piero Quatto. 2015. Fleissâ€™ kappa statistic without paradoxes. Quality & Quantity 49 (2015), 463â€“470. [52] Amir Hossein Ghapanchi. 2015. Predicting software future sustainability: A longitudinal perspective. Information Systems 49 (2015), 40â€“51. [53] Sean Goggins, Kevin Lumbard, and Matt Germonprez. 2021. Open source community health: Analytical metrics and their corresponding narratives. In 2021 IEEE/ACM 4th International Workshop on Software Health in Projects, Ecosystems and Communities (SoHeal). IEEE, 25â€“33. [54] Software Improvement Group. 2025. State of Software 2025: A Global Report on the Hidden Costs and Risks of Software. https://www.softwareimprovementgroup.com/wp-content/uploads/State-of-software-2025.pdf, last visited: May 08. [55] Aakanshi Gupta, Rashmi Gandhi, Nishtha Jatana, Divya Jatain, Sandeep Kumar Panda, and Janjhyam Venkata Naga Ramesh. 2023. A severity assessment of python code smells. IEEE Access 11 (2023), 119146â€“119160. [56] Md Shariful Haque, Jeff Carver, and Travis Atkison. 2018. Causes, impacts, and detection approaches of code smell: a survey. In Proceedings of the 2018 ACM Southeast Conference. 1â€“8. [57] Mohammed Mehedi Hasan, Hao Li, Emad Fallahzadeh, Gopi Krishnan Rajbahadur, Bram Adams, and A. E Hassan. 2025. The replication package of our study on MCP Servers. https://github.com/SAILResearch/replication-25-mcpserver-empirical-study, last visited: Jun 11. [58] Ahmed E Hassan, Gustavo A Oliva, Dayi Lin, Boyuan Chen, Zhen Ming, et al. 2024. Rethinking software engineering in the foundation model era: From task-driven ai copilots to goal-driven ai pair programmers. arXiv preprint arXiv:2404.10225 (2024). [59] Runzhi He, Hao He, Yuxia Zhang, and Minghui Zhou. 2023. Automating dependency updates in practice: An exploratory study on github dependabot. IEEE Transactions on Software Engineering 49, 8 (2023), 4004â€“4022. [60] Israel Herraiz, Jesus M Gonzalez-Barahona, and Gregorio Robles. 2008. Determinism and evolution. In Proceedings of the 2008 international working conference on Mining software repositories. 1â€“10. [61] Michael Hilton, Timothy Tunnell, Kai Huang, Darko Marinov, and Danny Dig. 2016. Usage, costs, and benefits of continuous integration in open-source projects. In Proceedings of the 31st IEEE/ACM international conference on automated software engineering. 426â€“437. [62] Xinyi Hou, Yanjie Zhao, Shenao Wang, and Haoyu Wang. 2025. Model Context Protocol (MCP): Landscape, Security Threats, and Future Research Directions. arXiv preprint arXiv:2503.23278 (2025). [63] IBM. 2025. Cost of a Data Breach Report 2024. https://www.ibm.com/reports/data-breach, last visited: May 27. [64] Samuel Idowu, Yorick Sens, Thorsten Berger, Jacob KrÃ¼ger, and Michael Vierhauser. 2024. A large-scale study of ml-related python projects. In Proceedings of the 39th ACM/SIGAPP Symposium on Applied Computing. 1272â€“1281. [65] Alphabet Inc. 2025. Security checklist. https://developer.android.com/privacy-and-security/security-tips, last visited: June 03. [66] Nenad Jovanovic, Christopher Kruegel, and Engin Kirda. 2006. Pixy: A static analysis tool for detecting web application vulnerabilities. In 2006 IEEE Symposium on Security and Privacy (S&Pâ€™06). IEEE, 6â€“pp. [67] Jaehun Jung, Faeze Brahman, and Yejin Choi. 2024. Trust or Escalate: LLM Judges with Provable Guarantees for Human Agreement. arXiv preprint arXiv:2407.18370 (2024). [68] Arvinder Kaur and Ruchikaa Nayyar. 2020. A comparative study of static code analysis tools for vulnerability detection in c/c++ and java source code. Procedia Computer Science 171 (2020), 2023â€“2029. [69] Noureddine Kerzazi, Foutse Khomh, and Bram Adams. 2014. Why do automated builds break? an empirical study. In

## 2014 IEEE international conference on software maintenance and evolution. IEEE, 41â€“50.

[70] Sonu Kumar, Anubhav Girdhar, Ritesh Patil, and Divyansh Tripathi. 2025. MCP Guardian: A Security-First Layer for Safeguarding MCP-Based AI System. arXiv preprint arXiv:2504.12757 (2025). [71] Invariant Lab. 2025. Introducing MCP-Scan: Protecting MCP with Invariant. https://invariantlabs.ai/blog/introducingmcp-scan, last visited: May 29. [72] Tuan Dung Lai, Anj Simmons, Scott Barnett, Jean-Guy Schneider, and Rajesh Vasa. 2024. Comparative analysis of real issues in open-source machine learning projects. Empirical Software Engineering 29, 3 (2024), 60.

[73] LangChain. 2025. LangChain: composable framework to build with LLMs. https://www.langchain.com/, last visited: Apr 23. [74] Jasmine Latendresse, Suhaib Mujahid, Diego Elias Costa, and Emad Shihab. 2022. Not all dependencies are equal: An empirical study on production dependencies in npm. In Proceedings of the 37th IEEE/ACM International Conference on Automated Software Engineering. 1â€“12. [75] Luigi Lavazza, Sandro Morasca, and Davide Tosi. 2021. Comparing static analysis and code smells as defect predictors: an empirical study. In IFIP international conference on open source systems. Springer, 1â€“15. [76] Valentina Lenarduzzi, Francesco Lomio, Heikki Huttunen, and Davide Taibi. 2020. Are sonarqube rules inducing bugs?. In 2020 IEEE 27th international conference on software analysis, evolution and reengineering (SANER). IEEE, 501â€“511. [77] Patrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Naman Goyal, Heinrich KÃ¼ttler, Mike Lewis, Wen-tau Yih, Tim RocktÃ¤schel, et al. 2020. Retrieval-augmented generation for knowledge-intensive nlp tasks. Advances in neural information processing systems 33 (2020), 9459â€“9474. [78] Hao Li and Cor-Paul Bezemer. 2025. Bridging the language gap: an empirical study of bindings for open source machine learning libraries across software package ecosystems. Empirical Software Engineering 30, 1 (2025), 6. [79] Hao Li, Cor-Paul Bezemer, and Ahmed E Hassan. 2024. Software Engineering and Foundation Models: Insights from Industry Blogs Using a Jury of Foundation Models. arXiv preprint arXiv:2410.09012 (2024). [80] Jiahuei Lin, Dayi Lin, Sky Zhang, and Ahmed E Hassan. 2024. Engineering AI Judge Systems. arXiv preprint arXiv:2411.17793 (2024). [81] LlamaIndex. 2025. LlamaIndex: LlamaIndex is the leading framework for building LLM-powered agents over your data with LLMs and workflows. https://docs.llamaindex.ai/en/stable/, last visited: Apr 23. [82] Google LLC. 2025. GenAI Toolbox: An introduction to MCP Toolbox. https://googleapis.github.io/genai-toolbox/ getting-started/introduction/, last visited: May 27. [83] Guillermo Macbeth, Eugenia Razumiejczyk, and RubÃ©n Daniel Ledesma. 2011. Cliffâ€™s Delta Calculator: A nonparametric effect size program for two groups of observations. Universitas Psychologica 10, 2 (2011), 545â€“555. [84] Thomas W MacFarland, Jan M Yates, Thomas W MacFarland, and Jan M Yates. 2016. Kruskalâ€“Wallis H-test for oneway analysis of variance (ANOVA) by ranks. Introduction to nonparametric statistics for the biological sciences using R (2016), 177â€“211. [85] Meta. 2025. Function Calling: Llama 3.1 models now officially supports function calling. https://github.com/abetlen/ llama-cpp-python/issues/1618, last visited: May 15. [86] Microsoft. 2025. Introducing Model Context Protocol (MCP) in Copilot Studio: Simplified Integration with AI Apps and Agents. https://www.microsoft.com/en-us/microsoft-copilot/blog/copilot-studio/introducing-model-contextprotocol-mcp-in-copilot-studio-simplified-integration-with-ai-apps-and-agents, last visited: Apr 23. [87] Microsoft. 2025. Plug, Play, and Prey: The security risks of the Model Context Protocol. https: //techcommunity.microsoft.com/blog/microsoftdefendercloudblog/plug-play-and-prey-the-security-risks-ofthe-model-context-protocol/4410829, last visited: May 18. [88] Vishal Midha and Prashant Palvia. 2012. Factors affecting the success of Open Source Software. Journal of Systems and Software 85, 4 (2012), 895â€“905. [89] Mitre. 2025. Common Weakness Enumeration:: A community developed list of SW & HW weakness that can become vulnerabilities. https://cwe.mitre.org/index.html, last visited: May 15. [90] Mohammed Abdul Moid, Abdullah Siraj, Mohd Farhaan Ali, and Ahmed Osman Amoodi. 2021. Predicting Stars on Open-Source GitHub Projects. In 2021 Smart Technologies, Communication and Robotics (STCR). IEEE, 1â€“9. [91] Dietmar PF MÃ¶ller. 2023. NIST cybersecurity framework and MITRE cybersecurity criteria. In Guide to Cybersecurity in Digital Transformation: Trends, Methods, Technologies, Applications and Best Practices. Springer, 231â€“271. [92] Suhaib Mujahid, Rabe Abdalkareem, and Emad Shihab. 2023. What are the characteristics of highly-selected packages? A case study on the npm ecosystem. Journal of Systems and Software 198 (2023), 111588. [93] Nuthan Munaiah, Steven Kroh, Craig Cabrey, and Meiyappan Nagappan. 2017. Curating github for engineered software projects. Empirical Software Engineering 22 (2017), 3219â€“3253. [94] Marvin MuÃ±oz BarÃ³n, Marvin Wyrich, and Stefan Wagner. 2020. An empirical validation of cognitive complexity as a measure of source code understandability. In Proceedings of the 14th ACM/IEEE international symposium on empirical software engineering and measurement (ESEM). 1â€“12. [95] Vineeth Sai Narajala and Idan Habler. 2025. Enterprise-Grade Security for the Model Context Protocol (MCP): Frameworks and Mitigation Strategies. arXiv preprint arXiv:2504.08623 (2025). [96] Mathew Nicho, Hussein Fakhry, and Charles Haiber. 2011. An integrated security governance framework for effective PCI DSS implementation. International Journal of Information Security and Privacy (IJISP) 5, 3 (2011), 50â€“67. [97] OpenAI. 2025. Function Calling: Enable models to fetch data and take actions. https://platform.openai.com/docs/ guides/function-calling, last visited: May 15.

[98] OpenAI. 2025. OpenAI Agents SDK: Model context protocol (MCP). https://openai.github.io/openai-agents-python/ mcp, last visited: Apr 23. [99] OpenAI, Josh Achiam, Steven Adler, Sandhini Agarwal, Lama Ahmad, Ilge Akkaya, Florencia Leoni Aleman, Diogo Almeida, Janko Altenschmidt, et al. 2024. GPT-4 Technical Report. arXiv preprint arXiv:2303.08774 (2024). [100] Fabio Palomba, Gabriele Bavota, Massimiliano Di Penta, Fausto Fasano, Rocco Oliveto, and Andrea De Lucia. 2018. On the diffuseness and the impact on maintainability of code smells: a large scale empirical investigation. In Proceedings of the 40th International Conference on Software Engineering. 482â€“482. [101] Thomas H Park, Brian Dorn, and Andrea Forte. 2015. An analysis of HTML and CSS syntax errors in a web development course. ACM Transactions on Computing Education (TOCE) 15, 1 (2015), 1â€“21. [102] PMD. 2025. An extensible multilanguage static code analyzer. https://pmd.github.io/, last visited: May 18. [103] LuÃ­s Prates and RÃºben Pereira. 2025. DevSecOps practices and tools. International Journal of Information Security 24,

## 1 (2025), 1â€“25.

[104] G Priyalakshmi and R Latha. 2018. Evaluation of software reusability based on coupling and cohesion. International Journal of Software Engineering and Knowledge Engineering 28, 10 (2018), 1455â€“1485. [105] Model Context Protocol. 2025. Model Context Protocol servers. https://github.com/modelcontextprotocol/servers, last visited: Apr 23. [106] Brandon Radosevich and John Halloran. 2025. MCP Safety Audit: LLMs with the Model Context Protocol Allow Major Security Exploits. arXiv preprint arXiv:2504.03767 (2025). [107] Akond Rahman, Chris Parnin, and Laurie Williams. 2019. The seven sins: Security smells in infrastructure as code scripts. In 2019 IEEE/ACM 41st International Conference on Software Engineering (ICSE). IEEE, 164â€“175. [108] Baishakhi Ray, Daryl Posnett, Vladimir Filkov, and Premkumar Devanbu. 2014. A large scale study of programming languages and code quality in github. In Proceedings of the 22nd ACM SIGSOFT international symposium on foundations of software engineering. 155â€“165. [109] Eric Raymond. 1999. The cathedral and the bazaar. Knowledge, Technology & Policy 12, 3 (1999), 23â€“49. [110] Andrew Rice, Edward Aftandilian, Ciera Jaspan, Emily Johnston, Michael Pradel, and Yulissa Arroyo-Paredes. 2017. Detecting argument selection defects. Proceedings of the ACM on Programming Languages 1, OOPSLA (2017), 1â€“22. [111] Chanchal K Roy, Minhaz F Zibran, and Rainer Koschke. 2014. The vision of software clone management: Past, present, and future (keynote paper). In 2014 Software Evolution Week-IEEE Conference on Software Maintenance, Reengineering, and Reverse Engineering (CSMR-WCRE). IEEE, 18â€“33. [112] Jukka Ruohonen. 2018. An empirical analysis of vulnerabilities in python packages for web applications. In 2018 9th International Workshop on Empirical Software Engineering in Practice (IWESEP). IEEE, 25â€“30. [113] Jukka Ruohonen, Kalle Hjerppe, and Kalle Rindell. 2021. A large-scale security-oriented static analysis of python packages in pypi. In 2021 18th International Conference on Privacy, Security and Trust (PST). IEEE, 1â€“10. [114] Graeme D Ruxton and Guy Beauchamp. 2008. Time for some a priori thinking about post hoc testing. Behavioral ecology 19, 3 (2008), 690â€“693. [115] Dhia Elhaq Rzig, Foyzul Hassan, Chetan Bansal, and Nachiappan Nagappan. 2022. Characterizing the usage of ci tools in ml projects. In Proceedings of the 16th ACM/IEEE International Symposium on Empirical Software Engineering and Measurement. 69â€“79. [116] Amir Saboury, Pooya Musavi, Foutse Khomh, and Giulio Antoniol. 2017. An empirical study of code smells in javascript projects. In 2017 IEEE 24th international conference on software analysis, evolution and reengineering (SANER). IEEE, 294â€“305. [117] Haya Samaana, Diego Elias Costa, Ahmad Abdellatif, and Emad Shihab. 2025. Opportunities and security risks of technical leverage: A replication study on the NPM ecosystem. Empirical Software Engineering 30, 3 (2025), 96. [118] VÃ­ctor Rea SÃ¡nchez, Pablo Neira Ayuso, JosÃ© A Galindo, and David Benavides. 2020. Open source adoption factorsâ€”a systematic literature review. IEEE Access 8 (2020), 94594â€“94609. [119] Aleksei Shestov, Rodion Levichev, Ravil Mussabayev, Evgeny Maslov, Pavel Zadorozhny, Anton Cheshkov, Rustam Mussabayev, Alymzhan Toleu, Gulmira Tolegen, and Alexander Krassovitskiy. 2025. Finetuning large language models for vulnerability detection. IEEE Access (2025). [120] Nima Shiri Harzevili, Alvine Boaye Belle, Junjie Wang, Song Wang, Zhen Ming Jiang, and Nachiappan Nagappan. 2024. A systematic literature review on automated software vulnerability detection using machine learning. Comput. Surveys 57, 3 (2024), 1â€“36. [121] Mohammed Latif Siddiq, Shafayat H Majumder, Maisha R Mim, Sourov Jajodia, and Joanna CS Santos. 2022. An empirical study of code smells in transformer-based code generation techniques. In 2022 IEEE 22nd International Working Conference on Source Code Analysis and Manipulation (SCAM). IEEE, 71â€“82. [122] Randeep Singh and Ashok Kumar. 2018. Identifying various code-smells and refactoring opportunities in objectoriented software system: a systematic literature review. International Journal on Future Revolution in Computer Science & Communication Engineering 8, March (2018), 62â€“74.

[123] Satwinder Singh and Sharanpreet Kaur. 2018. A systematic literature review: Refactoring for disclosing code smells in object oriented software. Ain Shams Engineering Journal 9, 4 (2018), 2129â€“2151. [124] sixsentix. 2025. Ten most expensive bugs in history (part 2). https://www.sixsentix.com/insights/ten-most-expensivebugs-in-history-part-2, last visited: May 27. [125] Justin Smith, Brittany Johnson, Emerson Murphy-Hill, Bill Chu, and Heather Richter Lipford. 2018. How developers diagnose potential security vulnerabilities with a static analysis tool. IEEE Transactions on Software Engineering 45, 9 (2018), 877â€“897. [126] smithery. 2025. Smithery: Your Agentâ€™s Gateway to the World. https://smithery.ai/, last visited: May 15. [127] SonarQube. 2025. SonarQube: Static Code Analysis. https://docs.sonarsource.com/sonarqube-server/latest/userguide/code-metrics/metrics-definition/#se-severity-types, last visited: May 14. [128] SonarQube. 2025. SonarQube: Static Code Analysis. https://docs.sonarsource.com/sonarqube-server/10.8/userguide/rules/security-related-rules, last visited: May 14. [129] Jairo Souza, Tales Alves, Robson Oliveira, Leopoldo Teixeira, and Baldoino Fonseca. 2024. Exception Miner: Multilanguage Static Analysis Tool to Identify Exception Handling Anti-Patterns. In SimpÃ³sio Brasileiro de Engenharia de Software (SBES). SBC, 741â€“747. [130] S, tefan StÄƒnciulescu, Likang Yin, and Vladimir Filkov. 2022. Code, quality, and process metrics in graduated and retired asfi projects. In Proceedings of the 30th ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 495â€“506. [131] Stripe. 2025. The Stripe Model Context Protocol server allows you to integrate with Stripe APIs through function calling. https://github.com/stripe/agent-toolkit/tree/main/modelcontextprotocol, last visited: May 27. [132] Sebastian Sztwiertnia, Maximilian GrÃ¼bel, Amine Chouchane, Daniel Sokolowski, Krishna Narasimhan, and Mira Mezini. 2021. Impact of programming languages on machine learning bugs. In Proceedings of the 1st ACM International Workshop on AI and Software Testing/Analysis. 9â€“12. [133] Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, TimothÃ©e Lacroix, Baptiste RoziÃ¨re, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, and Guillaume Lample. 2023. LLaMA: Open and Efficient Foundation Language Models. arXiv preprint arXiv:2302.13971 (2023). [134] Michele Tufano, Fabio Palomba, Gabriele Bavota, Rocco Oliveto, Massimiliano Di Penta, Andrea De Lucia, and Denys Poshyvanyk. 2015. When and why your code starts to smell bad. In 2015 IEEE/ACM 37th IEEE International Conference on Software Engineering, Vol. 1. IEEE, 403â€“414. [135] Marat Valiev, Bogdan Vasilescu, and James Herbsleb. 2018. Ecosystem-level determinants of sustained activity in open-source projects: A case study of the PyPI ecosystem. In Proceedings of the 2018 26th ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 644â€“655. [136] Bart Van Oort, LuÃ­s Cruz, MaurÃ­cio Aniche, and Arie Van Deursen. 2021. The prevalence of code smells in machine learning projects. In 2021 IEEE/ACM 1st workshop on AI engineering-software engineering for AI (WAIN). IEEE, 1â€“8. [137] Morteza Verdi, Ashkan Sami, Jafar Akhondali, Foutse Khomh, Gias Uddin, and Alireza Karami Motlagh. 2020. An empirical study of c++ vulnerabilities in crowd-sourced code examples. IEEE Transactions on Software Engineering 48,

## 5 (2020), 1497â€“1514.

[138] James Walden. 2020. The impact of a major security event on an open source project: The case of OpenSSL. In Proceedings of the 17th international conference on mining software repositories. 409â€“419. [139] Haoyu Wang, Hao Li, Li Li, Yao Guo, and Guoai Xu. 2018. Why are android apps removed from google play? a large-scale empirical study. In Proceedings of the 15th International Conference on Mining Software Repositories. 231â€“242. [140] Weichao Wang, Zhaopeng Meng, Zan Wang, Shuang Liu, and Jianye Hao. 2019. LoopFix: An approach to automatic repair of buggy loops. Journal of Systems and Software 156 (2019), 100â€“112. [141] Yingxu Wang and Vincent Chiew. 2013. Empirical studies on the functional complexity of software in large-scale software systems. In Advances in Abstract Intelligence and Soft Computing. IGI Global Scientific Publishing, 174â€“192. [142] Thomas Weber, Maximilian Brandmaier, Albrecht Schmidt, and Sven Mayer. 2024. Significant productivity gains through programming with large language models. Proceedings of the ACM on Human-Computer Interaction 8, EICS (2024), 1â€“29. [143] Katrine Wist, Malene Helsem, and Danilo Gligoroski. 2021. Vulnerability analysis of 2500 docker hub images. In Advances in Security, Networks, and Internet of Things: Proceedings from SAMâ€™20, ICWNâ€™20, ICOMPâ€™20, and ESCSâ€™20. Springer, 307â€“327. [144] Di Wu, Fangwen Mu, Lin Shi, Zhaoqiang Guo, Kui Liu, Weiguang Zhuang, Yuqi Zhong, and Li Zhang. 2024. iSMELL: Assembling LLMs with Expert Toolsets for Code Smell Detection and Refactoring. In Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering. 1345â€“1357. [145] Shijie Wu, Ozan Irsoy, Steven Lu, Vadim Dabravolski, Mark Dredze, Sebastian Gehrmann, Prabhanjan Kambadur, David Rosenberg, and Gideon Mann. 2023. Bloomberggpt: A large language model for finance. arXiv preprint

arXiv:2303.17564 (2023). [146] Wenxin Xiao, Hao He, Weiwei Xu, Yuxia Zhang, and Minghui Zhou. 2023. How early participation determines long-term sustained activity in github projects?. In Proceedings of the 31st ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering. 29â€“41. [147] Pravin Singh Yadav, Rajwant Singh Rao, Alok Mishra, and Manjari Gupta. 2024. Machine learning-based methods for code smell detection: a survey. Applied Sciences 14, 14 (2024), 6149. [148] Mehmet Ali YalÃ§inkaya and Ecir UÄŸur KÃ¼Ã§Ã¼ksille. 2024. Artificial Intelligence and Dynamic Analysis-Based Web Application Vulnerability Scanner. ISeCure 16, 1 (2024). [149] Aiko Yamashita and Steve Counsell. 2013. Code smells as system-level indicators of maintainability: An empirical study. Journal of Systems and Software 86, 10 (2013), 2639â€“2653. [150] Aiko Yamashita and Leon Moonen. 2012. Do code smells reflect important maintainability aspects?. In 2012 28th IEEE international conference on software maintenance (ICSM). IEEE, 306â€“315. [151] Ping Yu, Yijian Wu, Jiahan Peng, Jian Zhang, and Peicheng Xie. 2023. Towards understanding fixes of sonarqube static analysis violations: A large-scale empirical study. In 2023 IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER). IEEE, 569â€“580. [152] Ahmed Zerouali, Eleni Constantinou, Tom Mens, Gregorio Robles, and JesÃºs GonzÃ¡lez-Barahona. 2018. An empirical analysis of technical lag in npm package dependencies. In International conference on software reuse. Springer, 95â€“110. [153] Ahmed Zerouali, Tom Mens, Alexandre Decan, and Coen De Roover. 2022. On the impact of security vulnerabilities in the npm and RubyGems dependency networks. Empirical Software Engineering 27, 5 (2022), 107. [154] Markus Zimmermann, Cristian-Alexandru Staicu, Cam Tenny, and Michael Pradel. 2019. Small world with high risks: A study of security threats in the npm ecosystem. In 28th USENIX security symposium (USENIX Security 19). 995â€“1010. [155] Weiqin Zou, Weiqiang Zhang, Xin Xia, Reid Holmes, and Zhenyu Chen. 2019. Branch use in practice: A large-scale empirical study of 2,923 projects on github. In 2019 IEEE 19th International Conference on Software Quality, Reliability and Security (QRS). IEEE, 306â€“317.